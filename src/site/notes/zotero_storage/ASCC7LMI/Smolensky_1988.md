---
{"dg-publish":true,"permalink":"/zotero-storage/ascc-7-lmi/smolensky-1988/","noteIcon":""}
---

---
> [!PDF|187,97,229] [[1988 - Editorial Commentary.pdf#page=1&annotation=640R|1988 - Editorial Commentary, p.1]]
> Parallel connectionist memory and linguistic processes are hypothesized to give rise to processes that are describable at a higher level as sequential rule application

Well, this is something I was so desperately looking for!

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=3&annotation=643R|1988 - Editorial Commentary, p.3]]
> cognitive descriptions are built of entities that are symbols both in the semantic sense of referring to external objects and in the syntactic sense of being operated upon by symbol manipulation

Defn of Symbolic Paradigm


> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=3&annotation=646R|1988 - Editorial Commentary, p.3]]
>  cognitive descriptions built up of entities that correspond to constituents of the symbols used in the symbolic paradigm; thesefine-grainedconstituents could be called subsymbols, and they are the activities of individual processing units in connectionist network

Defn of Subsymbolism

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=3&annotation=649R|1988 - Editorial Commentary, p.3]]
> Subsymbols are not operated upon by symbol manipulation: They participate in numerical - not symbolic computation

Noice!
> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=5&annotation=657R|1988 - Editorial Commentary, p.5]]
> The neural architecture hypothesis: (To be rejected.) The intuitive processor for a particular task uses the same architecture that the brain uses for that task

Why reject this, tho? Perhaps coz he wants another level in-between? 

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=5&annotation=660R|1988 - Editorial Commentary, p.5]]
> but for problem solving, language, and many others (6) simply cannot do the necessary work at the present time.

typical Neuro-symbolicist?


> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=6&annotation=663R|1988 - Editorial Commentary, p.6]]
> (8) c. > [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=6&annotation=666R|1988 - Editorial Commentary, p.6]]
> The subconceptual level hypothesis: Complete, formal, and precise descriptions of the intuitive
> 
> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=7&annotation=669R|1988 - Editorial Commentary, p.7]]
> processor are generally tractable not at the conceptual level, but only at the subconceptual level

No idea why "Complete"

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=7&annotation=932R|1988 - Editorial Commentary, p.7]]
> The intuitive processor is a subconceptual connectionist dynamical system that does not admit a complete, formal, and precise conceptual-level description.


> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=7&annotation=935R|1988 - Editorial Commentary, p.7]]
> > Valid connectionist models are merely implementa- tions,  for a certain kind of parallel hardware, of  sym- bolic programs that provide exact and complete accounts of behavior at the conceptual level
> 
> 


> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=7&annotation=682R|1988 - Editorial Commentary, p.7]]
> Which activity patterns actually correspond to particular concepts or elements of the problem domain

Q

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=9&annotation=685R|1988 - Editorial Commentary, p.9]]
>  It is not clear how to make this correspondence precise. Does the activity of a unit correspond to the membrane potential at the cell body? Or the time-averaged firing rate of the neuron? Or the population-averaged firing rate of many neurons? Since the integration of signals between dendritic trees is probably more like the linear integration appearing in quasilinear dynamical


> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=9&annotation=953R|1988 - Editorial Commentary, p.9]]
> > Table 1.




> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=9&annotation=688R|1988 - Editorial Commentary, p.9]]
> The general principles of computation at the subconceptual level - computation in high-dimensional, high-complexity dynamical systems - must apply to computation in the brain; these principles are likely to be necessary, if not sufficient, to understand neural computation. 

Study Dynamical Systems Theory Some time? 


> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=9&annotation=706R|1988 - Editorial Commentary, p.9]]
> s stated earlier, on semantic measures, the subsymbolic level seems closer to the conceptual level, whereas on syntactic measures, it seems closer to the neural level

Aha!


> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=9&annotation=709R|1988 - Editorial Commentary, p.9]]
> Neurons located in 2+1-d space

Well..?

[ChatGPT](https://chatgpt.com/c/6723d7bd-b284-800b-97b3-933a3828456a)![Attachments/1988 - Editorial Commentary.jpg](/img/user/Attachments/1988%20-%20Editorial%20Commentary.jpg)

[[1988 - Editorial Commentary.pdf#page=9&rect=31,75,317,224&color=important|1988 - Editorial Commentary, p.9]]

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=10&annotation=712R|1988 - Editorial Commentary, p.10]]
>  discussed in the remainder of the article. Imagine three physical systems: a brain that is executing some cognitive process, a massively parallel connectionist computer running a subsymbolic model of that process, and a von Neumann computer running a symbolic model of the same process.

Example? 


> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=12&annotation=715R|1988 - Editorial Commentary, p.12]]
>  How would the two formalisms communicate? How would the hybrid system evolve with experience, reflecting the development of intuition and the subsequent remission of conscious rule application? How would the hybrid system elucidate the fallibility of actual human rule application (e.g., logic)? How would the hybrid system get us closer to understanding how conscious rule application is achieved neurally?

Q for the Neuro-Symbolicists

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=13&annotation=718R|1988 - Editorial Commentary, p.13]]
> the creativity of intuition can be exploited while its unreliability can be controlled.



> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=14&annotation=721R|1988 - Editorial Commentary, p.14]]
> l with those enforcing a wide variety of other constraints. S-knowledge can be acquired (once the linguistic skills on which it depends have been encoded into P-knowledge, of course) much more rapidly.

Wait, this is helluva interesting!


> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=14&annotation=724R|1988 - Editorial Commentary, p.14]]
>  
> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=14&annotation=729R|1988 - Editorial Commentary, p.14]]
>  nonmonotonicity is a fundamental property of subsymbolic inference.


> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=15&annotation=732R|1988 - Editorial Commentary, p.15]]
> . To the extent that the cognitive system meets its goal conditions in various environmental conditions, its internal states are veridical representations of the corresponding environmental states, with respect to the given goal conditions.

WRT? why? #Q 
"Veridical"

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=17&annotation=735R|1988 - Editorial Commentary, p.17]]
> In the symbolic paradigm, the context of a symbol is manifest around it and consists of other symbols; in the subsymbolic paradigm, the context of a symbol is manifest inside it and consists of subsymbols.



> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=18&annotation=738R|1988 - Editorial Commentary, p.18]]
> tial behavior. Recently Jordan (1986) has shown how a subsymbolic approach can give "for free" co-articulation effects where the manner in which actions are executed is influenced by future actions. Such effects are just what should come automatically from implementing serial behavior in a fundamentally parallel machine. Jordan's trick is to view the connectionist system as evolving continuously in time, with the task being the generation of a continuous trajectory through state space, a trajectory that meets as boundary conditions certain constraints, for example, that the discrete times 1, 2, ••• the system state must be in regions corresponding to the actions Av A

ok, nice, somewhat in the direction


> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=18&annotation=741R|1988 - Editorial Commentary, p.18]]
> A natural way to look at the knowledge stored in connections is to view each connection as a soft constrain

Yes...

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=18&annotation=744R|1988 - Editorial Commentary, p.18]]
> But soft constraints have no implications singly; any one can be overridden by the others. It is only the entire set of soft constraints that has any implications

Duhem? #Q 


![Attachments/1988 - Editorial Commentary 1.jpg](/img/user/Attachments/1988%20-%20Editorial%20Commentary%201.jpg)

[[1988 - Editorial Commentary.pdf#page=20&rect=35,336,301,432&color=important|1988 - Editorial Commentary, p.20]]



> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=20&annotation=747R|1988 - Editorial Commentary, p.20]]
> ion. In Section 7.2 it was pointed out that states of a subsymbolic model can be approximately analyzed as superpositions of vectors with individual conceptual-level semantic



> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=21&annotation=750R|1988 - Editorial Commentary, p.21]]
> Categories (it turns out) are attractors in connectionist dynamical systems: states that "suck in" to a common place

----
### Antony and Levine

1. Conflict between two approaches
2. Conflict: Disagreement about the level of analysis for (ACCURATE, COMPLETE) account of cog-processes. 

They say these two are incompatible

Mark of a domain shift can't be purely semantic

Are these non-syntactic mechanism "sub-conceptual"?

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=24&annotation=763R|1988 - Editorial Commentary, p.24]]
> The relation between the two paradigms, Smolensky argues, is analogous to the relation between classical and quantum mechanics: The symbolic model gives an approximately true description of the goings-on precisely characterized by a mathematical description of the dynamical systems that actually run intuitive cognitive processes. But there's the rub. Given the radical difference between the mechanisms and mode of explanation posited by the symbolic and the connectionist paradigms, what could it mean to say that, from a connectionist perspective, a symbolic theory is even "approximately" true?

huh?

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=24&annotation=766R|1988 - Editorial Commentary, p.24]]
> . If, on the other hand, both models yield explanatory insight into the workings of the mind, though at different levels of description, then we must understand connectionist models as implementation models

As if that's a problem? "Mere" implementations?

---
### Belew

---
> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=26&annotation=769R|1988 - Editorial Commentary, p.26]]
>  Subsymbolic models rest on the assumption that some of the most interesting cognitive phenomena cannot be modeled in terms of symbol manipulation (Smolensky presents this as point 7c); that is, the rejection of Newell's Physical System Hypothesis (1980) (which Smolensky effectively restates as his strawman point 3a).

Interesting Stuff: Fact check this!

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=4&annotation=941R|1988 - Editorial Commentary, p.4]]
> > Rules formulated in natural language can provide an effective formalization of cultural knowledge.

Is that the same? 

as “**the necessary and sufficient condition for a physical system to exhibit general intelligent action is that it be a physical symbol system**"

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=66&annotation=950R|1988 - Editorial Commentary, p.66]]
> > Belew

No reply to the allegations. 


the rest is just appreciating it

---

[[Credit-Assignment\|Credit-Assignment]]

---
### Cleland

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=28&annotation=777R|1988 - Editorial Commentary, p.28]]
> The problem is that the manner in which macrophysics is reducible to microphysics is not at all obvious. As traditionally construed, reducibility involves biconditional correlations (based on definition or law) between every reduced property and some reducing property. Unfortunately, despite the fact that many people are committed to the notion that microphysics is more fundamental than macrophysics, no one has been able to state any biconditional bridge laws which will actually effect the reduction of macrophysical properties to microphysical properties. In the absence of such laws it is very hard to see how the claim that the microphysical is more fundamental than the macrophysical can be justified. Indeed this state of affairs has led some philosophers to conclude that microphysics is not the more fundamental science (Horgan 1982).

Outrageous, def not boring, but also, so radically wrong that I am surprised someone can think this. 
#Q 

---
### Dreyfus and Dreyfus

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=31&annotation=780R|1988 - Editorial Commentary, p.31]]
> Connectionism can be understood as the most serious challenge to representationalism to have emerged on the cognitive science scene

Connectionism vs Repr.?
Repr. = Classical Cognitivism (Symbolism)


hidden units pick out...
> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=32&annotation=783R|1988 - Editorial Commentary, p.32]]
> context-free invariant features of the domain, which is the implicit commitment of the representationalism characteristic of cognitive science


----
### Freeman

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=33&annotation=786R|1988 - Editorial Commentary, p.33]]
> Smolensky's Table 1 should, in my opinion, have all pluses; this can be done with some minor redefinition of terms.

See how he deals with it 

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=9&annotation=953R|1988 - Editorial Commentary, p.9]]
> > Table 1.
> 
> 

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=66&annotation=956R|1988 - Editorial Commentary, p.66]]
> > Freeman 
> 
> 

not discussed, but he wants to represent the SOTA and some will change to "+" if you add multiple modules to the connectionist models. 
See..

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=65&annotation=959R|1988 - Editorial Commentary, p.65]]
> > Den Uyl makes the important point that Table 1 (target article) is based on typical current connectionist models that consist of a single module; if future models involve multiple modules, some of the '—'s in the table will change to '+'s. Table 1 is deliberately chosen to reflect the current state of the art, and will need to be kept up to date


### Golden

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=35&annotation=944R|1988 - Editorial Commentary, p.35]]
> > Continuity Is necessary for representing partial (real-valued) beliefs. As noted above, statistical inference differs from logical inference in its ability to represent and manipulate "partial beliefs" in propositions. Logical inference' can only approximately model statistical inference, but statistical inference can yield exactly the same answers as logical inference. Accordingly, the following revised version of Smolensky's subsymbolic hypothesis is suggested: A revised subsymbolic hypothesis. The intuitive processor is a connectionist dynamical system that is designed to solve statistical pattern recognition problems. This revised subsymbolic hypothesis demonstrates more directly the incompatibility of the subsymbolic and symbolic paradigms as described by Smolensky in the target articl



> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=35&annotation=789R|1988 - Editorial Commentary, p.35]]
> . The reason why Smolensky's hypothesis (10) must be rejected is that, according to this revised hypothesis, the intuitive processor is representing and manipulating "partial beliefs" (i.e., belief functions whose range is continuous and not discrete) which cannot be done by a rule-governed processor.

Go back to 10 and check it. 

he wants to reformulate
> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=7&annotation=935R|1988 - Editorial Commentary, p.7]]
> > Valid connectionist models are merely implementa- tions,  for a certain kind of parallel hardware, of  sym- bolic programs that provide exact and complete accounts of behavior at the conceptual level
> 
> 


### Doug

---



> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=37&annotation=792R|1988 - Editorial Commentary, p.37]]
> (e.g., variable binding, a touchstone of symbolic processing2 )

Variable binding is the process of temporarily associating (binding) a variable with a specific value or entity, allowing that association to be maintained and used across different processing steps.

Classical Example:

- "John loves Mary"
- Need to bind:
    - AGENT role to "John"
    - PATIENT role to "Mary"
    - ACTION to "loves"

In Symbolic Systems:

- Relatively straightforward through explicit variable assignment
- Example: loves(John, Mary)
----
### Hanson

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=38&annotation=805R|1988 - Editorial Commentary, p.38]]
> strong implementational view of connectionism."

What are some others? 

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=38&annotation=813R|1988 - Editorial Commentary, p.38]]
> ect. One presupposition of Smolensky's approach seems to be that symbolist (rule-based) accounts of psychological phenomena are correct, complete, consistent, and served up on a silver platter.

Wait, where?

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=39&annotation=816R|1988 - Editorial Commentary, p.39]]
> What then distinguishes the connectionist representations from any other kind? 

Yes, exactly my question, the feeling is, this guy is dead right. 


---
### Lakoff

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=39&annotation=819R|1988 - Editorial Commentary, p.39]]
> recursive function theory

aha...!

> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=40&annotation=822R|1988 - Editorial Commentary, p.40]]
>  cognitive topology



----
### Lehnert


> [!PDF|187, 97, 229] [[1988 - Editorial Commentary.pdf#page=41&annotation=825R|1988 - Editorial Commentary, p.41]]
> > e representational problems.


----
### Lycan

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=43&annotation=841R|1988 - Editorial Commentary, p.43]]
>  Though the subsymbolic paradigm allows for higher-level intentional reference to the external world by regions of hardware however scattered, such reference could not (according to the paradigm) be characterized in the terms normally considered appropriate to the computationally relevant higher level. As Dennett (1986, p. 69) has noted, the "brain-thingamabob [that] refers to Chicago" would per se have to be described statistically and in terms of the whole connectionist system or a very large mass of it

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=43&annotation=854R|1988 - Editorial Commentary, p.43]]
>  "anomalism of the mental

Wat this

- There are no strict deterministic laws relating mental events
- While there may be physical laws and mind-body correlations
- There can't be strict psychological laws

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=43&annotation=857R|1988 - Editorial Commentary, p.43]]
> the subsymbolic paradigm is right, then there are no strict psychological laws that can be couched in commonsensical English or even in real-time linear-computational terms

Wait, what kind of "Psychological Laws" were people looking for? 


---
### Nelson

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=45&annotation=860R|1988 - Editorial Commentary, p.45]]
>  parallel (of course, as Smolensky says, what counts as parallel and serial depends on the level of description)

where?

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=46&annotation=868R|1988 - Editorial Commentary, p.46]]
>  follow Pylyshyn (1984) in suspecting that connectionist models are, qua explanations, of what he calls the "functional architecture" type. A necessary condition for cognitive modeling is that it appeals to the information-bearing content of representations. Put more formally, representations should be semantically interpretable essentially in the sense of model theory (or better, in the sense of some theory of reference that unfortunately does not exist yet); otherwise they are not fit operands of cognitive activity but just causal links in the functional architecture level. Furthermore, if Pylyshyn is right, connectionism cannot explain intentional attitudes

In sense of Model Theory?

Intentional Attitudes? 
Intentional attitudes (beliefs, desires) require semantic content, which connectionist models allegedly lack!

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=46&annotation=876R|1988 - Editorial Commentary, p.46]]
> logic nets

explain

---
### Prince and Pinker

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=47&annotation=879R|1988 - Editorial Commentary, p.47]]
> Connectionist models that are restricted to associations among subsymbols are demonstrably inadequate. Considef these problems

What is a wickel feature?

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=47&annotation=947R|1988 - Editorial Commentary, p.47]]
> > , "unvoicedunvoiced-voiced" is one of the Wickelfeatures activated for stay
> 
> 

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=47&annotation=882R|1988 - Editorial Commentary, p.47]]
>  The model can learn bizarre, nonexistent morphological rules (e.g., reverse the order of the phonemes of the stem) as easily as common rules (e.g., do nothing to the stem; add d to the stem). Some rules (e.g., reduplicate the last syllable) can't be learned at all

Wat? 

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=47&annotation=890R|1988 - Editorial Commentary, p.47]]
> t is easy to conceive of hypothetical languages in which speakers compose words by probabilistically superimposing bits of material into any one of a family of related combination


> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=47&annotation=893R|1988 - Editorial Commentary, p.47]]
> epending on the frequencies of competing generalizations they have been exposed to. It is significant that human languages don't work that way


Yeah ok, so wat? 

---
### Rueckl


> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=50&annotation=896R|1988 - Editorial Commentary, p.50]]
> . A crucial issue here is whether connectionist models should be seen as competing with symbolic models, or if instead connectionist models are merely implementations of symbolic models at a lower level of description

why do you see "mere" Implementation in a derogatory sense? 


> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=54&annotation=899R|1988 - Editorial Commentary, p.54]]
> In connectionist models, by contrast, there are no discrete, independently manipulable symbols that refer to external objects. Nor are there discrete, independently manipulable clusters of elements (or "subsymbols") which may be viewed as doing the work of symbols. When a network that had previously said yes in response to "Did the hippie touch the debutante?" is retrained to say no, it will generally not be the case that there is some stable, identifiable cluster of elements which represent the proposition that the hippie touched the debutante, both before and after the retraining. And when a network that was previously unable to give sensible answers to questions about echidnas is trained or reprogrammed to give such answers, there typically will not be any identifiable cluster of elements which have taken on the role of referring to echidnas. Instead, what happens in both of these cases is that there is a widespread readjustment of weights throughout the network. As Smolensky notes, the representation of information in connectionist models (particularly in parallel distributed processing style models) is widely distributed, with each unit participating in the representation of many different aspects of the total information represented in the system. This radical disparity between strategies of representation in symbolic and PDP models makes a smooth reduction - or indeed any reduction - of symbols to elements (or to patterns of activity) extremely implausible. Rather, I submit, the relation between mental symbols and connectionist elements (or patterns of activity) is akin to the relation between caloric and molecular motion. If this is right, then in those domains where connectionist models prove to be empirically superior to symbolic alternatives, the inference to draw is that mental symbols do not exis



---
### Reply 

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=59&annotation=902R|1988 - Editorial Commentary, p.59]]
> The notion of implementation is provided primarily by the von Neumann computer; throughout this discussion I will take "implementation" to mean exactly what it means in that context.1 For my own purposes, the crucial aspect of the implementation relation is this. Suppose we have a physical system S which at some level of description L^ is performing exactly the computation JJL; that is, if we write down the laws governing the dynamics and interactions of those aspects of the system state that are characteristic of level L , we find these processes to be exactly described by u,. If p, is an implementation of M, we are guaranteed the following: The states of this same system S have characteristics at a higher level LM which evolve and interact exactly according to M: These characteristics define a description of S at the higher level L M for which M is a complete, formal, and precise account of the system's

Berry Interesting!


> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=60&annotation=962R|1988 - Editorial Commentary, p.60]]
> > Table 2. A
> 
> 

Lays it out!


> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=61&annotation=905R|1988 - Editorial Commentary, p.61]]
>  Among these limits are: The number of connectionist units or the strength of connection approaches infinity (allowing "soft" properties to become "hard," and allowing memory capacity limits to be idealized away for "competence" theory), the relaxation or learning time approaches infinity (allowing, e.g., stochastic inference or learning to converge to theoretically known limits), and the overlap (inner product) of vectors stored in memory approaches zero (orthogonality: eliminating interference of items in memory).

Whence the Limit? 

> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=62&annotation=908R|1988 - Editorial Commentary, p.62]]
> The target article stated that PTC rejects "blandly ecumenical" views; this term was intended to cover both the cohabitation version of revisionism and implementationalism



> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=63&annotation=921R|1988 - Editorial Commentary, p.63]]
> . In fact, these terms refer to paradigms for cognitive modeling, not levels. The editor is right to question whether "subsymbolic" refers to a lower level than "symbolic": It does not

lol wat? 

Reification in science occurs when abstract concepts or theoretical models are treated as if they have a concrete, real existence.


> [!PDF|255, 208, 0] [[1988 - Editorial Commentary.pdf#page=69&annotation=924R|1988 - Editorial Commentary, p.69]]
> > he comments of McCarthy about unary fixation and lack of "elaboration tolerance" seem to be on target.

look into this!