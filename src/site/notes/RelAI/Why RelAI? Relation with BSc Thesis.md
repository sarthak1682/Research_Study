---
{"dg-publish":true,"permalink":"/rel-ai/why-rel-ai-relation-with-b-sc-thesis/","noteIcon":""}
---


---


I intentionally present my argument in a simple Q&A format to ensure it is crystal clear.

Why am I pursuing my MSc in Informatics? 
My initial plan for it was to study the mathematical and philosophical foundations of AI, while trying to think about how it can help with scientific discovery, as I described in my Bewerbungsschreiben [BewMSc] in Jan'24.  

The original motive, naive though it may sound, was to stress test the leading Deep Neural Network (DNN) architectures by applying them to scientific problems, identifying their shortcomings, and subsequently attempting to formalize improved DNNs.

Math and Philosophy (esp. Phil. of Science) were supposed to help formulate the problems. 
A simple example is applying Graph Neural Nets (GNNs) to Quantum Chemistry for Molecular Property Predictions. 

All in all, the goal, to dramatise a bit, also happens to be the title of one of my recent favourite talks [CranmerApr24], "The Next Great Scientific Theory is Hiding Inside a Neural Network" (AI4Science) (and it would be fascinating to find it (Explainable AI)). 

How does RelAI fit into this threefold Plan? 

To the best of my understanding, my research will touch on the safety (with mathematical foundations) and responsibility (algorithmic decision making) themes of the relAI program. By nature, I am more inclined toward the foundational aspects.

A more detailed take is the following (caution: not exhaustive!)

Math (safety)- Prof. Kutyniok's Group and Prof. Ghoshdastidar's Group. Math of ML, Theory of Deep Learning (esp. Generalization and Robustness) and GNNs seem interesting. 

AI4Science (a testing ground for algorithms, potential for uncovering novel problems)- 
Although not directly under the relAI umbrella, a lot of relAI Professors (Fellows) are pursuing this direction independently. Both the Directors, Prof. G端nnemann (Molecular Property Prediction: DimeNet, GemNet etc.) and  Prof. Kutyniok (PDEs, Physical Law Learning, Imaging Problems), have already published on the topic. I am becoming more and more inclined towards GNNs [ICLR21Bronstein], due to its utility and mathematical formulation. 

Philosophy: It doesn't directly involve relAI but yet is quite important, simply because it makes one reflect on what one is doing. I agree with the philosopher Daniel Dennett that "There is no such thing as philosophy-free science; there is only science whose philosophical baggage is taken on board without examination.", I believe that what we are doing in foundations will be illuminated a lot by conceptual clarifications, the defining task of philosophy. Questions such as "What is a (causal) explanation", "What can we expect to learn from data alone" deserve their place in the wider discourse. Not to mention there have already been a couple of engagements from ML Folks with MCMP [MCMPMarch23], [MCMLJune23]. Also, I have a rough idea for a new Turing test, which I want to discuss with them [TuringTest]. 


Am I already doing something about it during this Summer-Semester? 
I am taking the following relevant courses/seminars this Summer. 
1) Math of ML by Prof Rauhut (At the end of analysing SVMs currently)
2) dl4science Seminar by Prof Cremers' Lab, where I am presenting GemNet, which came out of Prof. G端nnemann's Lab. GemNet lies at the intersection of foundations (Theory of GNNs) and AI4Science (Molecular Interaction Prediction). 
3) GenAI by Prof. Ommer (listed as a foundational Course on relAI Website)
4) ML by Prof. Tresp 
5) Quantum Computing by Prof. Kranzlm端ller
6) Philosophy of ML Reading Group with Dr. Sterkenburg: My recommendation for paper (on artificial scientist) was immediately selected as a choice of reading, despite my being a novice. 

I want to study Analysis II, Linear Algebra II and Geometric Deep Learning (GDL) during my Summer Vacation. I also want to have studied Functional Analysis before my MSc Thesis begins (Wise-25/26), so that I can look further into the theoretical and practical aspects of GNNs. 

A tentative plan, highlighting courses/seminars/practicals important to relAI can be found on my website. [MScPlan]

Note_1: I was not sure at the start of the semester if I would get credited for MathofML or dl4science, I ended up pursuing them anyway, because I find them important in themselves. 

Are there other related questions that I find interesting? 
A Question that always baffled me was how is it that the brain runs for an hour with the same energy that GPT uses for producing an answer of ca. 30 words, not to mention the adverse environmental effects. Prof. Kutyniok's work on limitations of digital hardware (for inverse problems) might ultimately end up shedding light on a part of the answer (by changing the model of computing from digital to analog/neuromorphic). Inventing hardware for realising BSS (Blum-Shub-Smale) Machines is as fascinating as it is radical. 

I think my previous question also connects with the foundational question in modern linguistics about why is that children are so efficient at acquiring a language, which lead researchers in the direction of searching for rich priors. GDL seems to be a DL-Flavoured attempt to do precisely this (encoding priors), which i find utterly fascinating. 

I think that insights into these two questions, taken together, might end up giving a more naturalistic spin to the in-vogue energy-guzzling LLMs, which are too permissive and flexible, too System-1 like, if one adopts the vocabulary of Kahneman et al. These insights might even allow us to move forward to System-2 like Behaviour, deliberate, reliable and (more) logic-like, eventually directing us towards AGI. 


What did I do in my BSc Thesis? 
Thesis Title: "Enhancing Data Valuation in Explainable AI with STI-KNN and Reinforcement Learning"
My Thesis was on Explainable AI at the AIML Chair (Prof. H端llermeier), specifically on combining SHAP-based approaches with RL Approaches. I designed an RL Environment from scratch (the toughest part), and compared A2C and PPO's performance on the task of Data Valuation. The RL Agent, with optimized hyperparameters, gave a performance increment of a whopping 19% compared to the baseline. The written part got a perfect grade of 1.0. 

Note_2: My advisor gave me an easier topic at the beginning, ended up giving me a more challenging one after two preliminary meetings. 

What am I expecting to get from RelAI? 

Since I did not have any experience growing up in being around scientists, I would greatly benefit from proper mentorship, group interactions and real hands-on research. I have the impression that what I have sketched out above is a gigantic undertaking, I expect that the professors will help me narrow the search space so that I can be immediately productive.  As an immigrant, I can't afford to not have a job, which takes up 20 hrs/week, getting a scholarship would buy me (much) more time for actual research before I begin my PhD. 

What am I missing at the moment?

At the moment, the biggest shortcoming for me is my limited to exposure to mathematics related to AI, which I am fully trying to overcome (cf. my MSc Program). 

In conclusion, why am I a suitable candidate? 

I think I am a suitable candidate because my motivations are organic and independent. The connections above make (at least) intuitive sense, albeit they are little too high level/big-picture-like. I respect, in fact revel in, the interdisciplinary nature of the field.  I think that tenacity/dedication is the minimal requirement of a graduate student, being resourceful/ knowing where to look is yet another, I believe I possess both of them, and I sincerely hope that I have provided enough evidence for you to believe the same. 






---
[BewMSc] [Bewerbungsschreiben](https://research-study-red.vercel.app/bewerbungsschreiben/)

 [CranmerApr24]   (https://www.youtube.com/watch?v=fk2r8y5TfNY&t=634s)
 [ICLR21Bronstein]  [ICLR 2021 Keynote - "Geometric Deep Learning: The Erlangen Programme of ML" - M Bronstein - YouTube]https://www.youtube.com/watch?v=w6Pw4MOzMuo
 It was informative, beautiful and inspiring all at the same time. (I thanked him, he retweeted!)). I am lready halfway through Prof. Leskovec's GNN-Course. 

 [MCMPMarch23]  [Epistemology and Theory of Machine Learning (23-24 March 2023) - Munich Center for Mathematical Philosophy (MCMP) - LMU Munich](https://www.mcmp.philosophie.uni-muenchen.de/events/archive/2023_workshops_conferences/ml_2023/index.html)
 
 [MCMLJune23]  https://www.mcmp.philosophie.uni-muenchen.de/events/archive/2023_workshops_conferences/mcml/index.html

[TuringTest] https://research-study-red.vercel.app/rel-ai/a-new-kind-of-turing-test/

 [MScPlan] https://research-study-red.vercel.app/course-plan/

---

[BewMSc] (https://research-study-red.vercel.app/bewerbungsschreiben/)

[CranmerApr24]  https://www.youtube.com/watch?v=fk2r8y5TfNY&t=634s

[ICLR21Bronstein] https://www.youtube.com/watch?v=w6Pw4MOzMuo
 It was informative, beautiful and inspiring all at the same time. (I thanked him, he retweeted!)). I am already halfway through Prof. Leskovec's GNN-Course. 

[MCMPMarch23] https://www.mcmp.philosophie.uni-muenchen.de/events/archive/2023_workshops_conferences/ml_2023/index.html
 
[MCMLJune23]  https://www.mcmp.philosophie.uni-muenchen.de/events/archive/2023_workshops_conferences/mcml/index.html

[TuringTest] https://research-study-red.vercel.app/rel-ai/a-new-kind-of-turing-test/

[MScPlan] https://research-study-red.vercel.app/course-plan/